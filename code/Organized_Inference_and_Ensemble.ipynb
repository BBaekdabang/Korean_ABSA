{   
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R1RAPnsKUIt"
      },
      "source": [
        "# import, pip, git clone, google drive mount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RDH-YQsQ2K0",
        "outputId": "67d11f9d-01e6-4191-c085-bfec7ab85295"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install sentencepiece\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Blw8cOeJX0dw",
        "outputId": "837d7617-015e-423d-8b62-3c7570d7a1c8"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/HappyBusDay/Korean_ABSA.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ir0LKINc4RBj",
        "outputId": "9be02ff7-448a-49d6-fe09-09c64c383323"
      },
      "outputs": [],
      "source": [
        "!gdown 1JDGHGCCsVk4A8DIqcIFd7lprBZtYEVVk\n",
        "!gdown 1jS-QdaNulhIkPxOCBZ-LJJdO9v9JkLu1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8LDwADWNMpsC"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import trange\n",
        "from transformers import XLMRobertaModel, AutoTokenizer\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import AdamW\n",
        "from datasets import load_metric\n",
        "from sklearn.metrics import f1_score\n",
        "import pandas as pd\n",
        "import copy\n",
        "import numpy as np\n",
        "from transformers import ElectraModel, ElectraTokenizer\n",
        "from transformers import AutoModel, ElectraTokenizer\n",
        "from collections import Counter\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1aWOyqC4nMD"
      },
      "source": [
        "# config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "urIlJHaHcO4A"
      },
      "outputs": [],
      "source": [
        "PADDING_TOKEN = 1\n",
        "S_OPEN_TOKEN = 0\n",
        "S_CLOSE_TOKEN = 2\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# pretrained_models\n",
        "model_ELECTRA = 'kykim/electra-kor-base'\n",
        "model_RoBERTa = 'xlm-roberta-base'\n",
        "model_DeBERTa = \"lighthouse/mdeberta-v3-base-kor-further\"\n",
        "\n",
        "entity_property_pair = [    # 카테고리의 수 = 25개\n",
        "     '패키지/구성품#다양성','본품#인지도','브랜드#디자인',\n",
        "     '패키지/구성품#편의성','제품 전체#디자인', '제품 전체#품질',\n",
        "     '패키지/구성품#품질','패키지/구성품#일반','본품#일반',\n",
        "     '패키지/구성품#디자인','본품#편의성','브랜드#품질',\n",
        "     '브랜드#인지도','본품#다양성','본품#디자인',\n",
        "     '제품 전체#다양성','본품#품질','제품 전체#인지도',\n",
        "     '패키지/구성품#가격','본품#가격','제품 전체#가격',\n",
        "     '브랜드#가격','브랜드#일반','제품 전체#일반','제품 전체#편의성'\n",
        "     ]\n",
        "\n",
        "tf_id_to_name = ['True', 'False']\n",
        "tf_name_to_id = {tf_id_to_name[i]: i for i in range(len(tf_id_to_name))}\n",
        "\n",
        "polarity_id_to_name = ['positive', 'negative', 'neutral']\n",
        "polarity_name_to_id = {polarity_id_to_name[i]: i for i in range(len(polarity_id_to_name))}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "special_tokens_dict = {\n",
        "    'additional_special_tokens': ['&name&', '&affiliation&', '&social-security-num&', '&tel-num&', '&card-num&', '&bank-account&', '&num&', '&online-account&']\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oB9RCISSzSY"
      },
      "source": [
        "# functions and classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGmH15hCeqhJ"
      },
      "source": [
        "## (func) jsonload, jsondump, jsonlload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6vGeHU4yP2Sg"
      },
      "outputs": [],
      "source": [
        "def jsonload(fname, encoding=\"utf-8\"):\n",
        "    with open(fname, encoding=encoding) as f:\n",
        "        j = json.load(f)\n",
        "    return j\n",
        "\n",
        "# json 개체를 파일이름으로 깔끔하게 저장\n",
        "def jsondump(j, fname):\n",
        "    with open(fname, \"w\", encoding=\"UTF8\") as f:\n",
        "        json.dump(j, f, ensure_ascii=False)\n",
        "\n",
        "# jsonl 파일 읽어서 list에 저장\n",
        "def jsonlload(fname, encoding=\"utf-8\"):\n",
        "    json_list = []\n",
        "    with open(fname, encoding=encoding) as f:\n",
        "        for line in f.readlines():\n",
        "            json_list.append(json.loads(line))\n",
        "    return json_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVaEgV7T_88W"
      },
      "source": [
        "## (func) tokenize_and_align_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KT6IfwXK_7iR"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(tokenizer, form, annotations, max_len):\n",
        "\n",
        "    entity_property_data_dict = {\n",
        "        'input_ids': [],\n",
        "        'attention_mask': [],\n",
        "        'label': []\n",
        "    }\n",
        "    polarity_data_dict = {\n",
        "        'input_ids': [],\n",
        "        'attention_mask': [],\n",
        "        'label': []\n",
        "    }\n",
        "\n",
        "    for pair in entity_property_pair:\n",
        "        isPairInOpinion = False\n",
        "        if pd.isna(form):\n",
        "            break\n",
        "        tokenized_data = tokenizer(form, pair, padding='max_length', max_length=max_len, truncation=True)\n",
        "        for annotation in annotations:\n",
        "            entity_property = annotation[0]\n",
        "            polarity = annotation[2]\n",
        "\n",
        "            if polarity == '------------':\n",
        "                continue\n",
        "\n",
        "            if entity_property == pair:\n",
        "                entity_property_data_dict['input_ids'].append(tokenized_data['input_ids'])\n",
        "                entity_property_data_dict['attention_mask'].append(tokenized_data['attention_mask'])\n",
        "                entity_property_data_dict['label'].append(tf_name_to_id['True'])\n",
        "\n",
        "                polarity_data_dict['input_ids'].append(tokenized_data['input_ids'])\n",
        "                polarity_data_dict['attention_mask'].append(tokenized_data['attention_mask'])\n",
        "                polarity_data_dict['label'].append(polarity_name_to_id[polarity])\n",
        "\n",
        "                isPairInOpinion = True\n",
        "                break\n",
        "\n",
        "        if isPairInOpinion is False:\n",
        "            entity_property_data_dict['input_ids'].append(tokenized_data['input_ids'])\n",
        "            entity_property_data_dict['attention_mask'].append(tokenized_data['attention_mask'])\n",
        "            entity_property_data_dict['label'].append(tf_name_to_id['False'])\n",
        "\n",
        "    return entity_property_data_dict, polarity_data_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLQn3LxWABNd"
      },
      "source": [
        "## (func) get_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ocqrb6QjACH_"
      },
      "outputs": [],
      "source": [
        "def get_dataset(raw_data, tokenizer, max_len):\n",
        "    input_ids_list = []\n",
        "    attention_mask_list = []\n",
        "    token_labels_list = []\n",
        "\n",
        "    polarity_input_ids_list = []\n",
        "    polarity_attention_mask_list = []\n",
        "    polarity_token_labels_list = []\n",
        "\n",
        "    for utterance in raw_data:\n",
        "        entity_property_data_dict, polarity_data_dict = tokenize_and_align_labels(tokenizer, utterance['sentence_form'], utterance['annotation'], max_len)\n",
        "        \n",
        "        input_ids_list.extend(entity_property_data_dict['input_ids'])\n",
        "        attention_mask_list.extend(entity_property_data_dict['attention_mask'])\n",
        "        token_labels_list.extend(entity_property_data_dict['label'])\n",
        "\n",
        "        polarity_input_ids_list.extend(polarity_data_dict['input_ids'])\n",
        "        polarity_attention_mask_list.extend(polarity_data_dict['attention_mask'])\n",
        "        polarity_token_labels_list.extend(polarity_data_dict['label'])\n",
        "\n",
        "    return TensorDataset(torch.tensor(input_ids_list), torch.tensor(attention_mask_list),\n",
        "                         torch.tensor(token_labels_list)), TensorDataset(torch.tensor(polarity_input_ids_list), torch.tensor(polarity_attention_mask_list),\n",
        "                         torch.tensor(polarity_token_labels_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN-xisSs07u9"
      },
      "source": [
        "## (class) SimpleClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_6cjejoy07u9"
      },
      "outputs": [],
      "source": [
        "# baseline\n",
        "class SimpleClassifier_Base(nn.Module):\n",
        "    def __init__(self, num_label, classifier_hidden):\n",
        "        super().__init__()\n",
        "\n",
        "        if layer_use == True:\n",
        "            self.dense1 = nn.Linear(classifier_hidden, classifier_hidden//2)\n",
        "            self.dense2 = nn.Linear(classifier_hidden//2, classifier_hidden//4)\n",
        "            self.dropout = nn.Dropout(dropout)\n",
        "            self.output = nn.Linear(classifier_hidden//4, num_label)\n",
        "        else:\n",
        "            self.dense = nn.Linear(classifier_hidden, classifier_hidden)\n",
        "            self.dropout = nn.Dropout(dropout)\n",
        "            self.output = nn.Linear(classifier_hidden, num_label)\n",
        "\n",
        "    def forward(self, features):\n",
        "        if layer_use == True:\n",
        "            x = features[:, 0, :]\n",
        "            x = self.dropout(x) # layer 1\n",
        "            x = self.dense1(x)\n",
        "            x = self.dropout(x) # layer 2\n",
        "            x = self.dense2(x)\n",
        "            x = torch.tanh(x)\n",
        "            x = self.dropout(x)\n",
        "            x = self.output(x)\n",
        "            return x\n",
        "\n",
        "        else:\n",
        "            x = features[:, 0, :]\n",
        "            x = self.dropout(x)\n",
        "            x = self.dense(x)\n",
        "            x = torch.tanh(x)\n",
        "            x = self.dropout(x)\n",
        "            x = self.output(x)\n",
        "            return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3vXCZTXxlQF"
      },
      "source": [
        "## (class) BaseClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAYwrlwFeH1s"
      },
      "source": [
        "* ELECTRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "t5zjxEHVeOvg"
      },
      "outputs": [],
      "source": [
        "class BaseClassifier_ELECTRA(nn.Module):\n",
        "    def __init__(self, num_label, len_tokenizer, hidden_size):\n",
        "        super(BaseClassifier_ELECTRA, self).__init__()\n",
        "\n",
        "        self.num_label = num_label\n",
        "        self.electra = AutoModel.from_pretrained( model_ELECTRA )\n",
        "        self.electra.resize_token_embeddings(len_tokenizer)\n",
        "        self.labels_classifier = SimpleClassifier_Base(self.num_label, hidden_size)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.electra(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=None\n",
        "        )\n",
        "\n",
        "        sequence_output = outputs[0]\n",
        "        logits = self.labels_classifier(sequence_output)\n",
        "\n",
        "        loss = None\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_label),\n",
        "                                                labels.view(-1))\n",
        "\n",
        "        return loss, logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pffiJkXleP2L"
      },
      "source": [
        "* DeBERTa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wGFm7RuqeRdX"
      },
      "outputs": [],
      "source": [
        "class BaseClassifier_DeBERTa(nn.Module):\n",
        "    def __init__(self, num_label, len_tokenizer, hidden_size):\n",
        "        super(BaseClassifier_DeBERTa, self).__init__()\n",
        "\n",
        "        self.num_label = num_label\n",
        "        self.deberta = AutoModel.from_pretrained( model_DeBERTa )\n",
        "        self.deberta.resize_token_embeddings(len_tokenizer)\n",
        "        self.labels_classifier = SimpleClassifier_Base(self.num_label, hidden_size)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.deberta(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=None\n",
        "        )\n",
        "\n",
        "        sequence_output = outputs[0]\n",
        "        logits = self.labels_classifier(sequence_output)\n",
        "\n",
        "        loss = None\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_label),\n",
        "                                                labels.view(-1))\n",
        "\n",
        "        return loss, logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JUsk646eTDI"
      },
      "source": [
        "* RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TSVeFQfY07vB"
      },
      "outputs": [],
      "source": [
        "class BaseClassifier_RoBERTa(nn.Module):\n",
        "    def __init__(self, num_label, len_tokenizer, hidden_size):\n",
        "        super(BaseClassifier_RoBERTa, self).__init__()\n",
        "\n",
        "        self.num_label = num_label\n",
        "        self.electra = AutoModel.from_pretrained( model_RoBERTa )\n",
        "        self.electra.resize_token_embeddings(len_tokenizer)\n",
        "        self.labels_classifier = SimpleClassifier_Base(self.num_label, hidden_size)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.electra(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=None\n",
        "        )\n",
        "\n",
        "        sequence_output = outputs[0]\n",
        "        logits = self.labels_classifier(sequence_output)\n",
        "\n",
        "        loss = None\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_label),\n",
        "                                                labels.view(-1))\n",
        "\n",
        "        return loss, logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsDitPTgeg1W"
      },
      "source": [
        "* ELECTRA (polarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "THoLuZaiVTZG"
      },
      "outputs": [],
      "source": [
        "class BaseClassifier_Pola(nn.Module):\n",
        "    def __init__(self, num_label, len_tokenizer, hidden_size):\n",
        "        super(BaseClassifier_Pola, self).__init__()\n",
        "\n",
        "        self.num_label = num_label\n",
        "        self.electra = AutoModel.from_pretrained( model_ELECTRA )\n",
        "        self.electra.resize_token_embeddings(len_tokenizer)\n",
        "        self.labels_classifier = SimpleClassifier_Base(self.num_label, hidden_size)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.electra(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=None\n",
        "        )\n",
        "\n",
        "        sequence_output = outputs[0]\n",
        "        logits = self.labels_classifier(sequence_output)\n",
        "\n",
        "        loss = None\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_label),\n",
        "                                                labels.view(-1))\n",
        "\n",
        "        return loss, logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pnl3uK3lYd5_"
      },
      "source": [
        "## (func) predict_from_korean_form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7HaNuMqrYh3R"
      },
      "outputs": [],
      "source": [
        "def predict_from_korean_form(tokenizer_cate, tokenizer_pola, ce_model, pc_model, data):\n",
        "    category_tokenizer = tokenizer_cate\n",
        "    polarity_tokenizer = tokenizer_pola\n",
        "\n",
        "    ce_model.to(device)\n",
        "    ce_model.eval()\n",
        "\n",
        "    for idx, sentence in enumerate(data):\n",
        "        form = sentence['sentence_form']\n",
        "        sentence['annotation'] = []\n",
        "        if type(form) != str:\n",
        "            print(\"form type is arong: \", form)\n",
        "            continue\n",
        "            \n",
        "        tmp= []\n",
        "        force_flag = False\n",
        "\n",
        "        # categoty(속성 범주)와 polarity(감성 범주) 모델을 각각 처리\n",
        "        for pair in entity_property_pair: \n",
        "            tokenized_data_cate = category_tokenizer(form, pair, padding='max_length', max_length = max_length, truncation=True)\n",
        "            tokenized_data_pola = polarity_tokenizer(form, pair, padding='max_length', max_length = polarity_max_length, truncation=True)\n",
        "            input_ids_cate = torch.tensor([tokenized_data_cate['input_ids']]).to(device)\n",
        "            input_ids_pola = torch.tensor([tokenized_data_pola['input_ids']]).to(device)\n",
        "            attention_mask_cate = torch.tensor([tokenized_data_cate['attention_mask']]).to(device)\n",
        "            attention_mask_pola = torch.tensor([tokenized_data_pola['attention_mask']]).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                _, ce_logits = ce_model(input_ids_cate, attention_mask_cate)\n",
        "                tmp.append( ce_logits[0][0] )\n",
        "            \n",
        "            # threshold 조정 시 ( default = 0 )\n",
        "            if ce_logits[0][0] > threshold: \n",
        "                ce_predictions = torch.argmax(ce_logits, dim = -1)\n",
        "                ce_result = tf_id_to_name[ce_predictions[0]]\n",
        "\n",
        "                if ce_result == 'True':\n",
        "                    force_flag = True\n",
        "                    with torch.no_grad():\n",
        "                        _, pc_logits = pc_model(input_ids_pola, attention_mask_pola)\n",
        "\n",
        "                    pc_predictions = torch.argmax(pc_logits, dim=-1)\n",
        "                    pc_result = polarity_id_to_name[pc_predictions[0]]\n",
        "\n",
        "                    sentence['annotation'].append([pair, pc_result])\n",
        "\n",
        "        # force evaluation of argument 사용 시 (default = False)\n",
        "        if force_use == True: \n",
        "            if force_flag == False:\n",
        "                tmp = torch.tensor(tmp)\n",
        "                pair = entity_property_pair[torch.argmax(tmp)]\n",
        "                with torch.no_grad():\n",
        "                    _, pc_logits = pc_model(input_ids_pola, attention_mask_pola)\n",
        "\n",
        "                pc_predictions = torch.argmax(pc_logits, dim=-1)\n",
        "                pc_result = polarity_id_to_name[pc_predictions[0]]\n",
        "                sentence['annotation'].append([pair, pc_result])\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFiEby13Ya9T"
      },
      "source": [
        "## (func) test_tentiment_analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Z8XTJOXPT6Ey"
      },
      "outputs": [],
      "source": [
        "def test_sentiment_analysis():\n",
        "    print(\"model pt path  =\", model_pt_path)\n",
        "    print(\"polarity model pt path =\", polarity_model_pt_path)\n",
        "\n",
        "    if model_kind == 'RoBERTa':\n",
        "        tokenizer = tokenizer_roberta\n",
        "        model = BaseClassifier_RoBERTa(len(tf_id_to_name), len(tokenizer), hidden_size)\n",
        "\n",
        "    elif model_kind == 'DeBERTa':\n",
        "        tokenizer = tokenizer_deberta\n",
        "        model = BaseClassifier_DeBERTa(len(tf_id_to_name), len(tokenizer), hidden_size)\n",
        "\n",
        "    else :\n",
        "        tokenizer = tokenizer_electra\n",
        "        model = BaseClassifier_ELECTRA(len(tf_id_to_name), len(tokenizer), hidden_size)\n",
        "        \n",
        "    model.load_state_dict(torch.load(model_pt_path , map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    polarity_model = BaseClassifier_Pola(len(polarity_id_to_name), len(tokenizer_electra), polarity_hidden_size)\n",
        "    polarity_model.load_state_dict(torch.load(polarity_model_pt_path , map_location=device))\n",
        "    polarity_model.to(device)\n",
        "    polarity_model.eval()\n",
        "\n",
        "    pred_data = predict_from_korean_form(tokenizer, tokenizer_electra, model, polarity_model, copy.deepcopy(test_data))\n",
        "\n",
        "    df_pred = pd.DataFrame(pred_data)\n",
        "\n",
        "    with open(save_path  + '.jsonl', 'w') as file:\n",
        "        for i in range( len(df_pred) ):\n",
        "            tmp = str(df_pred['annotation'][i]).replace(\"\\'\", \"\\\"\").replace('None', 'null')\n",
        "            file.write(  '{'+'\\\"id\\\": \\\"nikluge-sa-2022-test-{0}\\\", \\\"sentence_form\\\": \\\"{1}\\\", \\\"annotation\\\": {2}'\\\n",
        "                .format( str(i+1).zfill(5)  ,   df_pred['sentence_form'][i], tmp ) +'}' ) \n",
        "            file.write(\"\\n\")\n",
        "\n",
        "    return df_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfPL32JHS12z"
      },
      "source": [
        "## (func) excute_ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "uEOpcfuKS02U"
      },
      "outputs": [],
      "source": [
        "def excute_ensemble(model_list):\n",
        "    dic_ensemble = {\n",
        "        'id' : [],\n",
        "        'sentence_form' : [],\n",
        "        'annotation' : []\n",
        "    }\n",
        "\n",
        "    models = model_list \n",
        "\n",
        "    for i in range(len(models[0])):\n",
        "        tmp_divide = []\n",
        "\n",
        "        for j in models:\n",
        "            tmp_divide.append( str(j['annotation'][i]) )\n",
        "\n",
        "        answer = Counter(tmp_divide).most_common(n=1)[0][0]\n",
        "\n",
        "        check =  str(tmp_divide).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").replace(\"\\'\", \"\").replace(\"\\\"\", \"\").replace(\" \", \"\")\n",
        "\n",
        "        if '[]' in answer and check is not \"\":\n",
        "            while '[]' in tmp_divide:\n",
        "                tmp_divide.remove('[]')\n",
        "            dic_ensemble['annotation'].append( tmp_divide[0] )\n",
        "        else:\n",
        "            dic_ensemble['annotation'].append( answer )\n",
        "        dic_ensemble['id'].append( j['id'][i] )\n",
        "        dic_ensemble['sentence_form'].append( j['sentence_form'][i] )\n",
        "\n",
        "    df_ensemble = pd.DataFrame( dic_ensemble )\n",
        "\n",
        "    return df_ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnqwINlgvwBK"
      },
      "source": [
        "## (func) save_jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KWWLnCivS02V"
      },
      "outputs": [],
      "source": [
        "def save_jsonl(df_model, name, path):\n",
        "    with open(\"{1}/{0}.jsonl\" .format(name, path), 'w') as file:\n",
        "        for i in range( len(df_model) ):\n",
        "            annos = df_model['annotation'][i]\n",
        "            str_annos = str(annos)\n",
        "            tmp = str_annos.replace(\"None\", \"null\").replace(\"\\'\", \"\\\"\")\n",
        "\n",
        "            file.write(  '{'+'\\\"id\\\": \\\"nikluge-sa-2022-{3}-{0}\\\", \\\"sentence_form\\\": \\\"{1}\\\", \\\"annotation\\\": {2}'\\\n",
        "                        .format( str(i+1).zfill(5), df_model['sentence_form'][i], tmp, name ) +'}' )\n",
        "            file.write(\"\\n\")\n",
        "\n",
        "# {\"id\": \"nikluge-sa-2022-dev-00001\", \"sentence_form\": \"깔끔하게 부직포 포장으로 되어 있어서 그냥 뜨거운 물에 풍덩 넣어놓고 좀 휘젓어주면 금방 우러난다.\", \"annotation\": [[\"본품#편의성\", [\"부직포 포장\", 5, 11], \"positive\"]]}\n",
        "# 0은 숫자, 1은 sentence, 2는 annotation, 3은 file_name(파일이름)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQjCES7DC95E"
      },
      "source": [
        "# Inference Start"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO8QhhHLUz2m"
      },
      "source": [
        "parameter 설명\n",
        "* model_kind (대소문자 구분)\n",
        "    - RoBERTa : RoBERTa pretrained model load\n",
        "    - DeBERTa : DeBERTa pretrained model load\n",
        "    - ELECTRA : ELECTRA pretrained model load\n",
        "* layer_use\n",
        "    - True : add 1 layer\n",
        "    - False : do not add layer (*default)\n",
        "* hidden_size\n",
        "    - defalut : 768 \n",
        "    - up sampling : 1000\n",
        "    - down sampling : 384\n",
        "* force_use\n",
        "    - True : force evalutation of argument\n",
        "    - False : do not force evaluation (*default)\n",
        "* threshold\n",
        "    - default : 0\n",
        "    - strict : 2 ~ 3\n",
        "* dropout\n",
        "    - default : 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xZWTokeT18Tt"
      },
      "outputs": [],
      "source": [
        "########## 입력하세요 ##########\n",
        "\n",
        "model_kind = 'ELECTRA'  # 대소문자 구분\n",
        "\n",
        "layer_use = False   # default = False\n",
        "hidden_size = 768   # default = 768\n",
        "force_use = False   # default = False\n",
        "threshold = 0       # default = 0\n",
        "dropout = 0.1       # default = 0.1\n",
        "\n",
        "model_pt_path = \"./kelec_cate_Gpu_data_drop0_5_epoch_14.pt.pt의 사본\"\n",
        "polarity_model_pt_path = \"./Ma_Deep_epoch_2.pt.pt의 사본\"\n",
        "\n",
        "save_path = './model_day'\n",
        "\n",
        "###############################\n",
        "\n",
        "if model_kind == 'RoBERTa':\n",
        "    max_length = 514\n",
        "else:\n",
        "    max_length = 256\n",
        "polarity_max_length = 256\n",
        "polarity_hidden_size = 768\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgpSv8fJ6YeD"
      },
      "source": [
        "* 1회만 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfmKM1HsTIhM"
      },
      "outputs": [],
      "source": [
        "tokenizer_roberta = AutoTokenizer.from_pretrained( model_RoBERTa )\n",
        "tokenizer_electra = AutoTokenizer.from_pretrained( model_ELECTRA )\n",
        "tokenizer_deberta = AutoTokenizer.from_pretrained( model_DeBERTa )\n",
        "\n",
        "num_added_toks_roberta = tokenizer_roberta.add_special_tokens(special_tokens_dict)\n",
        "num_added_toks_electra = tokenizer_electra.add_special_tokens(special_tokens_dict)\n",
        "num_added_toks_deberta = tokenizer_deberta.add_special_tokens(special_tokens_dict)\n",
        "\n",
        "test_data_path = './Korean_ABSA/data/test_data.jsonl'\n",
        "test_data = jsonlload(test_data_path)\n",
        "\n",
        "entity_property_test_data_roberta, polarity_test_data_roberta = get_dataset(test_data, tokenizer_roberta, max_length)  # max_length = 514\n",
        "entity_property_test_data_electra, polarity_test_data_electra = get_dataset(test_data, tokenizer_electra, max_length)  # max_length = 256\n",
        "entity_property_test_data_deberta, polarity_test_data_deberta = get_dataset(test_data, tokenizer_deberta, max_length)  # max_length = 256\n",
        "\n",
        "entity_property_test_dataloader_roberta = DataLoader(entity_property_test_data_roberta, shuffle=True, batch_size=batch_size)\n",
        "entity_property_test_dataloader_electra = DataLoader(entity_property_test_data_electra, shuffle=True, batch_size=batch_size)\n",
        "entity_property_test_dataloader_deberta = DataLoader(entity_property_test_data_deberta, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "polarity_test_dataloader = DataLoader(polarity_test_data_electra, shuffle=True,batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621,
          "referenced_widgets": [
            "60927b0c3ad14ac68d66a87a6134eecc",
            "2fe734a06dde4a5e9ea842ffb2a175eb",
            "223ea8f1f1b84103a9e28b9901d6545f",
            "0b1a6db96e424ce8af9c66f08ed45959",
            "2445db0270e0481d983d8a442b365030",
            "98e85003710d4f38a1690b373a1b9169",
            "0d35196c0e4343deb198d63460ae2d41",
            "36b28d2a0a8a4eb598a824d357658453",
            "63585082f3af4f94a9d32bf78f6a1f77",
            "9a1de72d28f3451f9f0c68996ab98d82",
            "8ec5b35232a7406886323feb12c84755"
          ]
        },
        "id": "Yw4-DqroTI2D",
        "outputId": "c1e3454e-6d0c-487b-b864-984efcdcb211"
      },
      "outputs": [],
      "source": [
        "test_sentiment_analysis()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDOdFMcp4L4Y"
      },
      "source": [
        "# Ensemble Start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "fo9LzlUF4LcR"
      },
      "outputs": [],
      "source": [
        "### 모델 이름과 경로를 입력하세요 ###\n",
        "\n",
        "model_happy = pd.DataFrame(jsonlload(\"./Korean_ABSA/jsonl_files/esb_1108_joyofvictory45_8.jsonl\"))\n",
        "model_bus   = pd.DataFrame(jsonlload(\"./Korean_ABSA/jsonl_files/esb_1106_terarosa39_2.jsonl\"))\n",
        "model_day   = pd.DataFrame(jsonlload(\"./model_day.jsonl\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "mqr9mfWT5lSQ"
      },
      "outputs": [],
      "source": [
        "########## 입력하세요 ##########\n",
        "\n",
        "model_list = [model_happy, model_bus, model_day]\n",
        "\n",
        "name = \"ensemble_model\"\n",
        "path = \".\"\n",
        "\n",
        "################################  path 마지막에 /는 빼주세요\n",
        "\n",
        "df_model = excute_ensemble(model_list)\n",
        "save_jsonl(df_model, name, path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIEaTzNJ4zsm"
      },
      "source": [
        "# Check Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "mcG_QLxo475e",
        "outputId": "07a3829c-670f-447d-dc08-5517d596829a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c8e3a1f2-5b76-4165-b06f-8e05b37d19b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence_form</th>\n",
              "      <th>annotation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nikluge-sa-2022-ensemble_model-00001</td>\n",
              "      <td>하나 사려고 알아보는 중인데 맘에드는거 발견</td>\n",
              "      <td>[[제품 전체#일반, positive]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nikluge-sa-2022-ensemble_model-00002</td>\n",
              "      <td>동양인 피부톤과 잘 어울리고 우아한 분위기를 풍긴다네?</td>\n",
              "      <td>[[본품#품질, positive]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nikluge-sa-2022-ensemble_model-00003</td>\n",
              "      <td>근데 이건 마르살라보다 더 지나친 색 같은데..</td>\n",
              "      <td>[[본품#일반, negative]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nikluge-sa-2022-ensemble_model-00004</td>\n",
              "      <td>나스 색조가 다 그렇지만서도 어데이셔스 라인은 진짜 색 기막히게 뽑는것 같다</td>\n",
              "      <td>[[본품#일반, positive]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nikluge-sa-2022-ensemble_model-00005</td>\n",
              "      <td>색상만 보면 이걸 어떻게 발라.. 싶겠지만 의외로 너무너무 괜찮다</td>\n",
              "      <td>[[본품#일반, positive]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2122</th>\n",
              "      <td>nikluge-sa-2022-ensemble_model-02123</td>\n",
              "      <td>간단한 충전으로 간편한 사용이 가능한거죠.</td>\n",
              "      <td>[[본품#편의성, positive]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2123</th>\n",
              "      <td>nikluge-sa-2022-ensemble_model-02124</td>\n",
              "      <td>눈을 가린 상태에서도 간편하게 조작이 가능하구요,</td>\n",
              "      <td>[[본품#편의성, positive]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2124</th>\n",
              "      <td>nikluge-sa-2022-ensemble_model-02125</td>\n",
              "      <td>다양한 마사지로 관자놀이부터 눈주변까지 부드럽고 강력한 마사지가 진행됩니다.</td>\n",
              "      <td>[[본품#품질, positive]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2125</th>\n",
              "      <td>nikluge-sa-2022-ensemble_model-02126</td>\n",
              "      <td>본체부터 케이블, 설명서까지 깔끔하게 정리되어 보관이 가능하니 더더 맘에 쏙 들어요.</td>\n",
              "      <td>[[패키지/구성품#일반, positive]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2126</th>\n",
              "      <td>nikluge-sa-2022-ensemble_model-02127</td>\n",
              "      <td>사이즈가 컴펙트하고 무게감도 부담없어 가방에 쏙 넣고 다니기도 좋아요.</td>\n",
              "      <td>[[패키지/구성품#편의성, positive]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2127 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8e3a1f2-5b76-4165-b06f-8e05b37d19b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c8e3a1f2-5b76-4165-b06f-8e05b37d19b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c8e3a1f2-5b76-4165-b06f-8e05b37d19b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                        id  \\\n",
              "0     nikluge-sa-2022-ensemble_model-00001   \n",
              "1     nikluge-sa-2022-ensemble_model-00002   \n",
              "2     nikluge-sa-2022-ensemble_model-00003   \n",
              "3     nikluge-sa-2022-ensemble_model-00004   \n",
              "4     nikluge-sa-2022-ensemble_model-00005   \n",
              "...                                    ...   \n",
              "2122  nikluge-sa-2022-ensemble_model-02123   \n",
              "2123  nikluge-sa-2022-ensemble_model-02124   \n",
              "2124  nikluge-sa-2022-ensemble_model-02125   \n",
              "2125  nikluge-sa-2022-ensemble_model-02126   \n",
              "2126  nikluge-sa-2022-ensemble_model-02127   \n",
              "\n",
              "                                        sentence_form  \\\n",
              "0                            하나 사려고 알아보는 중인데 맘에드는거 발견   \n",
              "1                      동양인 피부톤과 잘 어울리고 우아한 분위기를 풍긴다네?   \n",
              "2                          근데 이건 마르살라보다 더 지나친 색 같은데..   \n",
              "3          나스 색조가 다 그렇지만서도 어데이셔스 라인은 진짜 색 기막히게 뽑는것 같다   \n",
              "4                색상만 보면 이걸 어떻게 발라.. 싶겠지만 의외로 너무너무 괜찮다   \n",
              "...                                               ...   \n",
              "2122                          간단한 충전으로 간편한 사용이 가능한거죠.   \n",
              "2123                      눈을 가린 상태에서도 간편하게 조작이 가능하구요,   \n",
              "2124       다양한 마사지로 관자놀이부터 눈주변까지 부드럽고 강력한 마사지가 진행됩니다.   \n",
              "2125  본체부터 케이블, 설명서까지 깔끔하게 정리되어 보관이 가능하니 더더 맘에 쏙 들어요.   \n",
              "2126          사이즈가 컴펙트하고 무게감도 부담없어 가방에 쏙 넣고 다니기도 좋아요.   \n",
              "\n",
              "                     annotation  \n",
              "0        [[제품 전체#일반, positive]]  \n",
              "1           [[본품#품질, positive]]  \n",
              "2           [[본품#일반, negative]]  \n",
              "3           [[본품#일반, positive]]  \n",
              "4           [[본품#일반, positive]]  \n",
              "...                         ...  \n",
              "2122       [[본품#편의성, positive]]  \n",
              "2123       [[본품#편의성, positive]]  \n",
              "2124        [[본품#품질, positive]]  \n",
              "2125   [[패키지/구성품#일반, positive]]  \n",
              "2126  [[패키지/구성품#편의성, positive]]  \n",
              "\n",
              "[2127 rows x 3 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_model = pd.DataFrame(jsonlload(\"./ensemble_model.jsonl\"))\n",
        "ensemble_model"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "5R1RAPnsKUIt",
        "-oB9RCISSzSY",
        "xGmH15hCeqhJ",
        "hVaEgV7T_88W",
        "vLQn3LxWABNd",
        "NN-xisSs07u9",
        "_3vXCZTXxlQF",
        "Pnl3uK3lYd5_",
        "xfPL32JHS12z"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('tf27')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "1d8015098d1dae84219b5f36314149636e9abcaade3eb06915d5127b55dee25b"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b1a6db96e424ce8af9c66f08ed45959": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a1de72d28f3451f9f0c68996ab98d82",
            "placeholder": "​",
            "style": "IPY_MODEL_8ec5b35232a7406886323feb12c84755",
            "value": " 473M/473M [00:07&lt;00:00, 58.1MB/s]"
          }
        },
        "0d35196c0e4343deb198d63460ae2d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "223ea8f1f1b84103a9e28b9901d6545f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36b28d2a0a8a4eb598a824d357658453",
            "max": 473243441,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63585082f3af4f94a9d32bf78f6a1f77",
            "value": 473243441
          }
        },
        "2445db0270e0481d983d8a442b365030": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fe734a06dde4a5e9ea842ffb2a175eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98e85003710d4f38a1690b373a1b9169",
            "placeholder": "​",
            "style": "IPY_MODEL_0d35196c0e4343deb198d63460ae2d41",
            "value": "Downloading: 100%"
          }
        },
        "36b28d2a0a8a4eb598a824d357658453": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60927b0c3ad14ac68d66a87a6134eecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2fe734a06dde4a5e9ea842ffb2a175eb",
              "IPY_MODEL_223ea8f1f1b84103a9e28b9901d6545f",
              "IPY_MODEL_0b1a6db96e424ce8af9c66f08ed45959"
            ],
            "layout": "IPY_MODEL_2445db0270e0481d983d8a442b365030"
          }
        },
        "63585082f3af4f94a9d32bf78f6a1f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ec5b35232a7406886323feb12c84755": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98e85003710d4f38a1690b373a1b9169": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a1de72d28f3451f9f0c68996ab98d82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
