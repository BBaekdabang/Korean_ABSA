{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5R1RAPnsKUIt",
        "-oB9RCISSzSY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#import, 설치, 구글 드라이브 마운트"
      ],
      "metadata": {
        "id": "5R1RAPnsKUIt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RDH-YQsQ2K0"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmtfOHQSQ-nS"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLnBHUF1eqZc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    { 
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LDwADWNMpsC"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import trange\n",
        "from transformers import XLMRobertaModel, AutoTokenizer\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import AdamW\n",
        "from datasets import load_metric\n",
        "from sklearn.metrics import f1_score\n",
        "import pandas as pd\n",
        "import copy\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import re"
      ]
    },
    { 
      "cell_type": "markdown",
      "source": [
        "# functions"
      ],
      "metadata": {
        "id": "-oB9RCISSzSY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGmH15hCeqhJ"
      },
      "source": [
        "json 및 jsonl 파일 read, write 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vGeHU4yP2Sg"
      },
      "outputs": [],
      "source": [
        "def jsonload(fname, encoding=\"utf-8\"):\n",
        "    with open(fname, encoding=encoding) as f:\n",
        "        j = json.load(f)\n",
        "    return j\n",
        "\n",
        "# json 개체를 파일이름으로 깔끔하게 저장\n",
        "def jsondump(j, fname):\n",
        "    with open(fname, \"w\", encoding=\"UTF8\") as f:\n",
        "        json.dump(j, f, ensure_ascii=False)\n",
        "\n",
        "# jsonl 파일 읽어서 list에 저장\n",
        "def jsonlload(fname, encoding=\"utf-8\"):\n",
        "    json_list = []\n",
        "    with open(fname, encoding=encoding) as f:\n",
        "        for line in f.readlines():\n",
        "            json_list.append(json.loads(line))\n",
        "    return json_list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "앙상블 round 함수"
      ],
      "metadata": {
        "id": "z_Z62lRWK2oK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "        round 함수 : model list에서 n번째 모델을 하나씩 빼면서 새로운 리스트 만든다\n",
        "        \n",
        "        models = [A, B, C, D]\n",
        "\n",
        "        models_1 = [B, C, D]\n",
        "        models_2 = [A, C, D]\n",
        "        models_3 = [A, B, D]\n",
        "        models_4 = [A, B, C]"
      ],
      "metadata": {
        "id": "Us3iRcPu9mNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def round(model_list):\n",
        "    round_model_list = [None] * len(model_list)\n",
        "\n",
        "    for idx in range(len(round_model_list)):\n",
        "        round_model_list[idx] = model_list[:idx] + model_list[idx+1:]\n",
        "    return round_model_list"
      ],
      "metadata": {
        "id": "z7m0BDQXK19A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "excute_ensemble, save_jsonl"
      ],
      "metadata": {
        "id": "xfPL32JHS12z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def excute_ensemble(automatic_ae):\n",
        "    dic_ae = {\n",
        "        'id' : [],\n",
        "        'sentence_form' : [],\n",
        "        'annotation' : []\n",
        "    }\n",
        "\n",
        "    models = automatic_ae \n",
        "\n",
        "\n",
        "    for i in range(len(models[0])):\n",
        "        tmp_divide = []\n",
        "\n",
        "        for j in models:\n",
        "            tmp_divide.append( str(j['annotation'][i]) )\n",
        "\n",
        "        answer = Counter(tmp_divide).most_common(n=1)[0][0]\n",
        "\n",
        "        check =  str(tmp_divide).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").replace(\"\\'\", \"\").replace(\"\\\"\", \"\").replace(\" \", \"\")\n",
        "\n",
        "        if '[]' in answer and check is not \"\":\n",
        "            while '[]' in tmp_divide:\n",
        "                tmp_divide.remove('[]')\n",
        "            dic_ae['annotation'].append( tmp_divide[0] )\n",
        "        else:\n",
        "            dic_ae['annotation'].append( answer )\n",
        "        dic_ae['id'].append( j['id'][i] )\n",
        "        dic_ae['sentence_form'].append( j['sentence_form'][i] )\n",
        "\n",
        "    df_ae = pd.DataFrame( dic_ae )\n",
        "\n",
        "    return df_ae"
      ],
      "metadata": {
        "id": "uEOpcfuKS02U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_jsonl(df_ae, name, path):\n",
        "\n",
        "    with open(\"{1}/{0}.jsonl\" .format(name, path), 'w') as file:\n",
        "        for i in range( len(df_ae) ):\n",
        "            annos = df_ae['annotation'][i]\n",
        "            str_annos = str(annos)\n",
        "            tmp = str_annos.replace(\"None\", \"null\").replace(\"\\'\", \"\\\"\")\n",
        "\n",
        "            file.write(  '{'+'\\\"id\\\": \\\"nikluge-sa-2022-{3}-{0}\\\", \\\"sentence_form\\\": \\\"{1}\\\", \\\"annotation\\\": {2}'\\\n",
        "                        .format( str(i+1).zfill(5)  ,   df_ae['sentence_form'][i], tmp, name ) +'}' )\n",
        "            file.write(\"\\n\")\n",
        "\n",
        "#{\"id\": \"nikluge-sa-2022-dev-00001\", \"sentence_form\": \"깔끔하게 부직포 포장으로 되어 있어서 그냥 뜨거운 물에 풍덩 넣어놓고 좀 휘젓어주면 금방 우러난다.\", \"annotation\": [[\"본품#편의성\", [\"부직포 포장\", 5, 11], \"positive\"]]}\n",
        "# 0은 숫자, 1은 sentence, 2는 annotation, 3은 file_name(파일이름)"
      ],
      "metadata": {
        "id": "KWWLnCivS02V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Files"
      ],
      "metadata": {
        "id": "B7FPY-S57Uev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 모델 이름과 주소를 입력하세요\n",
        "\n",
        "model_A = pd.DataFrame(jsonlload(\"/content/model_A.jsonl\"))\n",
        "model_B = pd.DataFrame(jsonlload(\"/content/model_B.jsonl\"))\n",
        "model_C = pd.DataFrame(jsonlload(\"/content/model_C.jsonl\"))"
      ],
      "metadata": {
        "id": "r2lG5_xj7stQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start Ensemble"
      ],
      "metadata": {
        "id": "fXtMkFn79Ync"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    round 함수 : model list에서 n번째 모델을 하나씩 빼면서 새로운 리스트 만든다\n",
        "\n",
        "    models = [A, B, C, D]\n",
        "\n",
        "    models_1 = [B, C, D]\n",
        "    models_2 = [A, C, D]\n",
        "    models_3 = [A, B, D]\n",
        "    models_4 = [A, B, C]"
      ],
      "metadata": {
        "id": "bmIVbbSr-Rq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble = [model_A, model_B, model_C]\n",
        "\n",
        "\n",
        "ensemble_round = round(ensemble)"
      ],
      "metadata": {
        "id": "35Qohy-h-Yo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model ensemble"
      ],
      "metadata": {
        "id": "Q2Tzr212evxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dic_ae = {\n",
        "    'id' : [],\n",
        "    'sentence_form' : [],\n",
        "    'annotation' : []\n",
        "}\n",
        "\n",
        "### 모델 리스트를 입력하세요 ###\n",
        "\n",
        "models = ensemble\n",
        "\n",
        "################################\n",
        "\n",
        "for i in range(len(models[0])):\n",
        "    tmp_divide = []\n",
        "\n",
        "    for j in models:  # 각 모델들에 있는 inference를 하나의 리스트에 모은다.\n",
        "        tmp_divide.append( str(j['annotation'][i]) )\n",
        "\n",
        "    answer = Counter(tmp_divide).most_common(n=1)[0][0] # 리스트에서 가장 많은 inference를 하드보팅 한다.\n",
        "\n",
        "    # annotation 유무를 확인한다.\n",
        "    check =  str(tmp_divide).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").replace(\"\\'\", \"\").replace(\"\\\"\", \"\").replace(\" \", \"\")\n",
        "\n",
        "    if '[]' in answer and check is not \"\":   # []이 하드보팅의 결과값이 된다면 다른 inference 값이 있는지 확인하고,\n",
        "        while '[]' in tmp_divide:            # 다른 inference 값이 있다면, 그 값을 답으로 추론한다.\n",
        "            tmp_divide.remove('[]')\n",
        "        dic_ae['annotation'].append( tmp_divide[0] )\n",
        "    else:\n",
        "        dic_ae['annotation'].append( answer )\n",
        "    dic_ae['id'].append( j['id'][i] )\n",
        "    dic_ae['sentence_form'].append( j['sentence_form'][i] )\n",
        "\n",
        "df_ae = pd.DataFrame( dic_ae )\n",
        "df_ae"
      ],
      "metadata": {
        "id": "Y8VO8-p-Ld7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# jsonl 파일로 저장하기\n",
        "\n",
        "\n",
        "### 파일 이름을 입력하세요 ###\n",
        "\n",
        "file_name = 'ensemble'   \n",
        "\n",
        "##############################\n",
        "\n",
        "\n",
        "with open('/content/{0}.jsonl' .format(file_name), 'w') as file:\n",
        "    for i in range( len(df_ae) ):\n",
        "        annos = df_ae['annotation'][i]\n",
        "        str_annos = str(annos)\n",
        "        tmp = str_annos.replace(\"None\", \"null\").replace(\"\\'\", \"\\\"\")\n",
        "\n",
        "        file.write(  '{'+'\\\"id\\\": \\\"nikluge-sa-2022-{3}-{0}\\\", \\\"sentence_form\\\": \\\"{1}\\\", \\\"annotation\\\": {2}'\\\n",
        "                    .format( str(i+1).zfill(5)  ,   df_ae['sentence_form'][i], tmp, file_name ) +'}' )\n",
        "        file.write(\"\\n\")\n",
        "\n",
        "# {\"id\": \"nikluge-sa-2022-dev-00001\", \"sentence_form\": \"깔끔하게 부직포 포장으로 되어 있어서 그냥 뜨거운 물에 풍덩 넣어놓고 좀 휘젓어주면 금방 우러난다.\", \"annotation\": [[\"본품#편의성\", [\"부직포 포장\", 5, 11], \"positive\"]]}\n",
        "\n",
        "# 0은 숫자, 1은 sentence, 2는 annotation, 3은 file_name(파일이름)"
      ],
      "metadata": {
        "id": "GM4cgNzfMdX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model round"
      ],
      "metadata": {
        "id": "3tNquQUSQwaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### round 할 모델 리스트를 입력하세요 ###\n",
        "\n",
        "model_lists = ensemble_round\n",
        "\n",
        "#########################################\n",
        "\n",
        "name = 'ensemble_round_'\n",
        "path = '/content'\n",
        "# path 마지막에 /는 빼주세요.\n",
        "\n",
        "\n",
        "for idx, i in enumerate(model_lists):\n",
        "    model = i\n",
        "    esb_model = excute_ensemble(model)\n",
        "    save_jsonl(esb_model, name+str(idx+1), path)"
      ],
      "metadata": {
        "id": "0BzU5CSyQ3hR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 잘 열리는지 test"
      ],
      "metadata": {
        "id": "hF3RtOQT5o4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test =  pd.DataFrame(jsonlload(\"/content/{0}.jsonl\". format(file_name)))\n",
        "df_test"
      ],
      "metadata": {
        "id": "ikzGIbTW5omN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 또 다른 시도"
      ],
      "metadata": {
        "id": "wf4lQ2wFDO7T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 만장일치"
      ],
      "metadata": {
        "id": "i_1eFseD0ZMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "만장일치인 정답만 답을 내고, 나머지 annotation은 []"
      ],
      "metadata": {
        "id": "DhQsz3pvEK-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 모델 리스트를 입력하세요 ###\n",
        "\n",
        "models = ensemble\n",
        "\n",
        "################################\n",
        "\n",
        "\n",
        "dic_ae = {\n",
        "    'id' : [],\n",
        "    'sentence_form' : [],\n",
        "    'annotation' : []\n",
        "}\n",
        "\n",
        "\n",
        "for i in range(len(models[0])):\n",
        "    tmp_divide = []\n",
        "\n",
        "    for j in models:        \n",
        "        tmp_divide.append( str(j['annotation'][i]) )\n",
        "\n",
        "    tmp_divide = set(tmp_divide)\n",
        "    \n",
        "    if len(tmp_divide) == 1:\n",
        "        dic_ae['annotation'].append( str(j['annotation'][i]) )\n",
        "    else:\n",
        "        dic_ae['annotation'].append( '[]' )\n",
        "    dic_ae['id'].append( j['id'][i] )\n",
        "    dic_ae['sentence_form'].append( j['sentence_form'][i] )\n",
        "\n",
        "\n",
        "df_ae = pd.DataFrame( dic_ae )\n",
        "df_ae"
      ],
      "metadata": {
        "id": "LIwIQO8q0fl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# category, polarity 각각 다수결"
      ],
      "metadata": {
        "id": "ymR1MwwjAs6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dic_ae = {\n",
        "    'id' : [],\n",
        "    'sentence_form' : [],\n",
        "    'annotation' : []\n",
        "}\n",
        "\n",
        "### 모델 리스트를 입력하세요 ###\n",
        "\n",
        "models = ensemble\n",
        "\n",
        "################################\n",
        "\n",
        "for p in range(len(models[0])):\n",
        "    tmp_list = []\n",
        "    tmp_divide = []\n",
        "\n",
        "    ##### cate 다수결\n",
        "    for j in models:   # tmp_divide = [ ['본품#일반', 'positive'], ['제품 전체#일반', 'positive'], ['본품#일반', 'negative'] ]     \n",
        "        tmp_divide.append( str(j['annotation'][p]) )   \n",
        "    dic_ae['id'].append( j['id'][p] )\n",
        "    dic_ae['sentence_form'].append( j['sentence_form'][p] )   \n",
        "    str_tmp_divide = str(tmp_divide)\n",
        "\n",
        "    tmp_cate = re.findall(\"[가-힣\\#\\/ ]+\", str_tmp_divide)\n",
        "     # tmp_cate = [ ['본품#일반'], ['제품 전체#일반'], ['본품#일반'] ]    \n",
        "\n",
        "    for j in range(len(tmp_cate)):\n",
        "        if ' ' in tmp_cate:\n",
        "            tmp_cate.remove(' ')\n",
        "    tmp_cate = list(set(tmp_cate))\n",
        "     # tmp_cate = [ ['본품#일반'], ['제품 전체#일반'] ]   중복 제거   \n",
        "    \n",
        "    picked_cate = []\n",
        "    for j in tmp_cate:\n",
        "        cate_count = str_tmp_divide.count(j)\n",
        "        if cate_count >= len(tmp_divide)//2+1 :   # 과반수 이상이면\n",
        "            picked_cate.append(j)\n",
        "            # picked_cate = [ ['본품#일반'] ]   과반수 이상이 가지고 있는 category만 pick\n",
        "\n",
        "    ##### pola 다수결\n",
        "    for idx, i in enumerate(picked_cate):\n",
        "        tmp_answer = []\n",
        "        pola_pos_count = 0\n",
        "        pola_neu_count = 0\n",
        "        pola_neg_count = 0\n",
        "\n",
        "        for j in tmp_divide:  \n",
        "            if str(i) in str(j):\n",
        "                if 'positive' in j:\n",
        "                    pola_pos_count += 1\n",
        "                if 'neutral' in j:\n",
        "                    pola_neu_count += 1\n",
        "                if 'negative' in j:\n",
        "                    pola_neg_count += 1\n",
        "            \n",
        "        if pola_pos_count >= pola_neu_count:\n",
        "            if pola_pos_count >= pola_neg_count:\n",
        "                pola_vote = 'positive'\n",
        "        elif pola_neu_count > pola_pos_count:\n",
        "            if  pola_neu_count > pola_neg_count:\n",
        "                pola_vote = 'neutral'\n",
        "        else:\n",
        "            pola_vote = 'negative'\n",
        "\n",
        "        tmp_answer.append( str(picked_cate[idx]) )\n",
        "        tmp_answer.append( str(pola_vote) )\n",
        "\n",
        "        tmp_list.append( tmp_answer )\n",
        "    \n",
        "    ##### 하나도 못잡은것 후처리\n",
        "    check =  str(tmp_divide).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").replace(\"\\'\", \"\").replace(\"\\\"\", \"\").replace(\" \", \"\")\n",
        "    if '[]' in str(tmp_list) and check is not \"\":\n",
        "        while '[]' in tmp_divide:\n",
        "            tmp_divide.remove('[]')\n",
        "        dic_ae['annotation'].append( tmp_divide[0] )\n",
        "    else:\n",
        "        dic_ae['annotation'].append( tmp_list )\n",
        "\n",
        "df_ae = pd.DataFrame( dic_ae )\n",
        "df_ae"
      ],
      "metadata": {
        "id": "h06l3Q9zA2Xp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
